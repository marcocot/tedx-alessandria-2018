# AI

Quanti di voi hanno visto il film Minority Report? Per chi non
l'avesse mai visto, la trama descrive un futuro distopico in cui la
polizia è capace di impedire gli omicidi prima ancora che questi
avvengano. In realtà ci siamo molto vicini: dal 2016[b] la polizia di
Chicago utilizza un software per prevenire il crimine assegnando un
punteggio ad ogni cittadino. In questo modo è possibile prevedere in
quali zone della città ci sarà una maggiore concentrazione di crimini: i
cittadini quindi sono schedati in base a quanto è probabile che possano
commettere attività criminali. Inquietante vero? E qui sorge spontaneo
chiedersi: è giusto essere giudicati prima ancora di aver commesso un
crimine? O[c], meglio, è giusto che per la salvaguardia dell’ordine
pubblico un computer ci possa“marchiare” come pericolosi, magari solo
perché abitiamo nel quartiere sbagliato o abbiamo la pelle di un altro
colore? Come insegnare l’etica La[d] grossa sfida che abbiamo davanti
oggi è quella di saper dare un “senso etico” a queste nuove macchine
pensanti. Se immaginiamo che già per noi è difficile riuscire ad
esprimere concetti come “morale”, “etica” o cosa è giusto o sbagliato
possiamo facilmente capire che lo è ancor di più riuscire ad insegnarlo
a un computer attraverso un calcolo matematico. Il mondo della
fantascienza ci ha insegnato che dobbiamo temere macchine che possano un
giorno acquisire coscienza e ribellarsi ai loro creatori, ma la realtà è
ben diversa: dobbiamo temere le macchine che hanno uno scopo che non è
in “linea” con il nostro senso etico e morale: un missile a guida
autonoma (o, per usare un eufemismo, “intelligente”) ha uno scopo ben
preciso, ma è pericoloso nel momento in cui il suo “scopo” siamo noi.
Stessa cosa per una macchina a guida autonoma: diventa pericolosa nel
momento in cui per salvare un pedone decide di sacrificare il guidatore
(o viceversa), in quel momento sta facendo una scelta morale e quella
scelta gliela abbiamo insegnata noi. Cosa ne pensano i grandi Vorrei
citare a tal proposito il pensiero di alcuni importanti personaggi,
alcuni a favore dell’AI e altri che sono totalmente contrari. Stephen
Hawking, ad esempio, ha teorizzato che se riuscissimo ad arrivare a
creare una intelligenza artificiale “completa” questa evolverebbe
autonomamente ad una velocità tale che potrebbe essere un rischio per la
nostra civiltà stessa. Dello stesso avviso è anche Elon Musk, fondatore
di Tesla e SpaceX, che ha addirittura immaginato scenari apocalittici di
esseri umani schiavi di macchine pensanti.

Del resto entrambi (insieme ad altri 98 influenti personaggi) nel 2015
hanno firmato una petizione alle Nazioni Unite chiedendo il bando
dell’uso dell’IA nello sviluppo di armi[e]: nella loro visione questo
tipo di armi porterà conflitti su più larga scala e una corsa agli
armamenti “intelligenti”.

Anche più catastrofico è stato Nick Bostrom, famoso filosofo svedese,
che nel 2016 scrisse “Superintelligence: Paths, Dangers, Strategies”,
bestseller per il New York Times, che si può riassumere con una
citazione (slide): “Siamo come bambini che giocano con una bomba”.

Tutti questi scienziati temono, quindi, che un giorno potremo arrivare a
creare macchine con un’intelligenza superiore alla nostra fino a
diventarne schiavi. Quello che evidenziano è un problema spesso
sottovalutato dalla ricerca scientifica: il vero pericolo è la velocità
con cui si evolve la tecnologia. Per fare un semplice paragone basti
pensare che si calcola che l’uomo ha “imparato” a parlare in circa
20.000 anni, mentre “AlphaGO”, un progetto realizzato da Google nel
2014, ha imparato autonomamente a giocare a Go (e a battere Lee Sedol,
18 volte campione del mondo) in un anno.

La vera differenza (ed il pericolo intrinseco) è che come esseri umani
siamo strettamente legati alla nostra evoluzione biologica, mentre un
algoritmo di IA è legato principalmente all’evoluzione tecnologica: se
normalmente per far fare qualcosa ad un computer dobbiamo programmarlo,
e quindi impartirgli istruzioni ben precise e ripetibili, con l’utilizzo
della IA il computer è in grado di ragionare autonomamente su un
problema e di trovare la soluzione più efficiente possibile. Quanto più
avanza la tecnologia, tanto più un computer è in grado di trovare
velocemente soluzioni sempre più efficienti.

Di totale altro avviso è, ad esempio, Steve Wozniak (fondatore di Apple
insieme a Jobs) che oggi, molto più pragmaticamente, crede che non
dobbiamo temere questa tecnologia, visto che prima di essere “realmente”
pericolosa ci vorranno almeno altri 20-30 anni di sviluppi: quello che
più realisticamente crede è che nei prossimi decenni si arriverà ad
avere computer con le stesse capacità intellettive di un bambino di 6
anni.

Dello stesso avviso è anche Ray Kurzweil, capo degli ingegneri di
Google, che prevede che arriveremo ad avere macchine con capacità
intellettive pari alle nostre non prima del 2030.

Tecnologicamente affascinante, ma non suona esattamente come minaccioso,
giusto? Conclusioni Personalmente sono affascinato dalle mille nuove
prospettive che questa tecnologia porterà nelle nostre vita: basti
pensare a come già oggi la nostra vita sta cambiando senza che,
probabilmente, ce ne rendiamo conto: macchine a guida autonoma,
assistenti vocali, videogames, sistemi di bordo degli aerei che
prendiamo quotidianamente e mille altri utilizzi.

Io[f], nel mio piccolo, sono piuttosto scettico nell’immaginare la
“distruzione dell’umanità” da parte di macchine senzienti. Esiste
certamente un problema morale e sociale legato all’uso di questa
tecnologia (basti pensare a quanti posti di lavoro, per esempio, sono a
rischio se dovessimo iniziare a spostare merci su camion totalmente a
guida autonoma!): per quanto è affascinante e ci fa volare con la
fantasia parlare di “cervelli elettronici”, in realtà quando parliamo di
Intelligenza Artificiale, stiamo parlando di analisi di dati, problem
solving ed automazione basata su dati, conoscenze ed esperienze. Tutta
roba molto più noiosa di quello che abbiamo visto in Terminator!

Quello che mi piacerebbe invece veder realizzato è sempre più la
possibilità di sfruttare queste tecnologie per migliorare le nostre
condizioni di vita. Ad esempio nel 2017 un team formato da scienziati
provenienti da Germania, Francia e Stati Uniti ha sperimentato
l’applicazione di algoritmi di intelligenza artificiale per
l’identificazione di melanomi maligni della pelle.

Durante questo studio sono stati presentati diversi casi ad un pool di
medici a cui è stato chiesto di diagnosticare, partendo da alcune foto,
la tipologia di melanoma ed eventualmente il trattamento da adottare: la
cosa sorprendente è che i medici sono stati in grado di riconoscere e,
virtualmente, trattare l’86% dei casi presentati … un computer ha
ottenuto invece il 95% di risposte corrette.

O, ancora, quest’anno una giovane e brillante startup di Rimini, che
ho avuto l’onore di poter seguire da vicino, ha brevettato un sistema in
grado di prevedere quelli che tecnicamente sono chiamati “bird strikes”,
cioè l’impatto di stormi di uccelli con aerei in fase di
decollo/atterraggio. Qualcuno ricorda il caso dell’aereo di linea che
nel 2009 è atterrato nel fiume Hudson? Ecco, quell’incidente, che
avrebbe potuto costare la vita a 190 persone, fu causato proprio da un
“bird strike” che distrusse entrambi i motori dell’aeroplano. Pensate
che, secondo dati Enac, solo nel 2014 si è calcolato che in Italia ci
sono stati oltre 300 incidenti per un costo di oltre 40 milioni di euro.
Da pilota di ultraleggeri vi posso garantire che non è piacevole
scontrarsi contro un oggetto che può generare mezza tonnellata di forza.

Quello che è riuscito a realizzare questa startup è un sistema di
monitoraggio in tempo reale capace di riconoscere autonomamente dei
“pattern”, cioè i comportamenti specifici del movimento degli uccelli e
di prevenire in anticipo quando uno stormo potrebbe essere un pericolo
per gli aerei in movimento.

Questo è quello che trovo veramente affascinante, un aiuto concreto
all’intelligenza umana: pensate quante vite si potrebbero salvare se
potessimo preventivamente diagnosticare malattie potenzialmente mortali
o evitare di fare atterrare un 737 su un fiume.

Nella mia vita mi occupo di sviluppo software. Ho iniziato questa
professione abbastanza da giovane facendo noiosissimi siti web; sono
cresciuto negli anni 80, agli albori del mondo ad 8 bit e oggi mi trovo
qui a parlare di cervelli virtuali che possono diagnosticare tumori
partendo da una fotografia. Sono il solo qui ad essere elettrizzato da
queste prospettive?

Quello[h] che immagino è un mondo in cui le macchine possano essere un
aiuto essenziale ed un supporto al genio dell’essere umano, un aiuto che
ci possa permettere un balzo in avanti nell’evoluzione. E’ una grossa
sfida quella che ci aspetta e il tempo sta correndo velocemente, è
arrivato il momento di capire quali sono le potenzialità della
tecnologia e capire come veramente poterla sfruttare al nostro servizio
senza diventarne schiavi.

In definitiva, diventeremo servi delle macchine, o saranno il gradino
che ci farà toccare le stelle?
